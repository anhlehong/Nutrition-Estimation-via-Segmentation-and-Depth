{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-image food volume estimation\n",
    "Using a  monocular depth estimation network and a segmentation network, we will estimate the volume of the food displayed in the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from food_volume_estimation.depth_estimation.custom_modules import *\n",
    "from food_volume_estimation.volume_estimator import VolumeEstimator\n",
    "from FoodSAM.FoodSAM_tools.enhance_semantic_masks import enhance_masks\n",
    "from FoodSAM.FoodSAM_tools.predict_semantic_mask import semantic_predict\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import argparse\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "import httpx\n",
    "\n",
    "from fastapi import FastAPI, HTTPException, UploadFile, File, Depends\n",
    "from pydantic import BaseModel\n",
    "from keras import backend as K\n",
    "from keras.models import Model, model_from_json\n",
    "from pyngrok import ngrok\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "# Th√™m ƒë∆∞·ªùng d·∫´n c√°c th∆∞ vi·ªán t√πy ch·ªânh\n",
    "sys.path.append('.')\n",
    "sys.path.append('./SAM')\n",
    "sys.path.append('./mmseg')\n",
    "\n",
    "# Import c√°c module c·∫ßn thi·∫øt\n",
    "\n",
    "# √Åp d·ª•ng nest_asyncio ƒë·ªÉ ch·∫°y FastAPI\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Ki·ªÉm tra GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Bi·∫øn to√†n c·ª•c cho estimator, graph, session\n",
    "estimator = None\n",
    "global_graph = None\n",
    "global_session = None\n",
    "\n",
    "\n",
    "def init_estimator():\n",
    "    \"\"\"Kh·ªüi t·∫°o estimator v·ªõi graph v√† session m·ªõi\"\"\"\n",
    "    global estimator, global_graph, global_session\n",
    "    # X√≥a graph v√† session hi·ªán t·∫°i\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # T·∫°o graph v√† session m·ªõi\n",
    "    global_graph = tf.Graph()\n",
    "    global_session = tf.Session(graph=global_graph)\n",
    "\n",
    "    with global_graph.as_default():\n",
    "        with global_session.as_default():\n",
    "            K.set_session(global_session)\n",
    "            depth_model_architecture = './models/fine_tune_food_videos/monovideo_fine_tune_food_videos.json'\n",
    "            depth_model_weights = './models/fine_tune_food_videos/monovideo_fine_tune_food_videos.h5'\n",
    "            estimator = VolumeEstimator(arg_init=False)\n",
    "            try:\n",
    "                with open(depth_model_architecture, 'r') as read_file:\n",
    "                    custom_losses = Losses()\n",
    "                    objs = {\n",
    "                        'ProjectionLayer': ProjectionLayer,\n",
    "                        'ReflectionPadding2D': ReflectionPadding2D,\n",
    "                        'InverseDepthNormalization': InverseDepthNormalization,\n",
    "                        'AugmentationLayer': AugmentationLayer,\n",
    "                        'compute_source_loss': custom_losses.compute_source_loss\n",
    "                    }\n",
    "                    model_architecture_json = json.load(read_file)\n",
    "                    estimator.monovideo = model_from_json(\n",
    "                        model_architecture_json, custom_objects=objs)\n",
    "                estimator._VolumeEstimator__set_weights_trainable(\n",
    "                    estimator.monovideo, False)\n",
    "                global_session.run(tf.global_variables_initializer())\n",
    "                estimator.monovideo.load_weights(depth_model_weights)\n",
    "                estimator.model_input_shape = estimator.monovideo.inputs[0].shape.as_list()[\n",
    "                    1:]\n",
    "                depth_net = estimator.monovideo.get_layer('depth_net')\n",
    "                estimator.depth_model = Model(\n",
    "                    inputs=depth_net.inputs, outputs=depth_net.outputs, name='depth_model')\n",
    "                MIN_DEPTH = 0.01\n",
    "                MAX_DEPTH = 10\n",
    "                estimator.min_disp = 1 / MAX_DEPTH\n",
    "                estimator.max_disp = 1 / MIN_DEPTH\n",
    "                estimator.gt_depth_scale = 0.35\n",
    "                estimator.relax_param = 0.01\n",
    "                print('[*] Loaded depth estimation model.')\n",
    "                # B·ªè graph.finalize() ƒë·ªÉ tr√°nh l·ªói\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading model: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "# H√†m ghi log\n",
    "\n",
    "\n",
    "def write_log(message):\n",
    "    log_file_path = \"debug/log.txt\"\n",
    "\n",
    "    # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
    "    os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
    "\n",
    "    # Th√™m timestamp cho log\n",
    "    timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "\n",
    "    # Format n·ªôi dung log\n",
    "    if isinstance(message, (dict, list)):\n",
    "        message_str = json.dumps(message, ensure_ascii=False, indent=2)\n",
    "    else:\n",
    "        message_str = str(message)\n",
    "\n",
    "    # Ghi v√†o file\n",
    "    with open(log_file_path, \"a\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(f\"{timestamp} {message_str}\\n\")\n",
    "\n",
    "    # In ra console\n",
    "    print(f\"{timestamp} {message_str}\")\n",
    "\n",
    "# H√†m x√≥a th∆∞ m·ª•c\n",
    "\n",
    "\n",
    "def clear_folder(folder_path: str):\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        for item in os.listdir(folder_path):\n",
    "            item_path = os.path.join(folder_path, item)\n",
    "            try:\n",
    "                if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "                    os.remove(item_path)\n",
    "                elif os.path.isdir(item_path):\n",
    "                    shutil.rmtree(item_path)\n",
    "            except Exception as e:\n",
    "                print(f\"L·ªói khi x√≥a {item_path}: {e}\")\n",
    "        print(f\"‚úÖ ƒê√£ x√≥a to√†n b·ªô n·ªôi dung trong th∆∞ m·ª•c '{folder_path}'.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Th∆∞ m·ª•c '{folder_path}' kh√¥ng t·ªìn t·∫°i.\")\n",
    "\n",
    "# H√†m l∆∞u mask t·ª´ SAM\n",
    "\n",
    "\n",
    "def write_masks_to_folder(masks: List[Dict[str, Any]], path: str) -> None:\n",
    "    header = \"id,area,bbox_x0,bbox_y0,bbox_w,bbox_h,point_input_x,point_input_y,predicted_iou,stability_score,crop_box_x0,crop_box_y0,crop_box_w,crop_box_h\"\n",
    "    metadata = [header]\n",
    "    os.makedirs(os.path.join(path, \"sam_mask\"), exist_ok=True)\n",
    "    masks_array = []\n",
    "    for i, mask_data in enumerate(masks):\n",
    "        mask = mask_data[\"segmentation\"]\n",
    "        masks_array.append(mask.copy())\n",
    "        filename = f\"{i}.png\"\n",
    "        cv2.imwrite(os.path.join(path, \"sam_mask\", filename), mask * 255)\n",
    "        mask_metadata = [\n",
    "            str(i),\n",
    "            str(mask_data[\"area\"]),\n",
    "            *[str(x) for x in mask_data[\"bbox\"]],\n",
    "            *[str(x) for x in mask_data[\"point_coords\"][0]],\n",
    "            str(mask_data[\"predicted_iou\"]),\n",
    "            str(mask_data[\"stability_score\"]),\n",
    "            *[str(x) for x in mask_data[\"crop_box\"]],\n",
    "        ]\n",
    "        row = \",\".join(mask_metadata)\n",
    "        metadata.append(row)\n",
    "    masks_array = np.stack(masks_array, axis=0)\n",
    "    np.save(os.path.join(path, \"sam_mask\", \"masks.npy\"), masks_array)\n",
    "    metadata_path = os.path.join(path, \"sam_metadata.csv\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(metadata))\n",
    "\n",
    "# H√†m ch·∫°y FoodSAM (PyTorch)\n",
    "\n",
    "\n",
    "def run_foodsam(image_path):\n",
    "    args = argparse.Namespace(\n",
    "        img_path=image_path,\n",
    "        output=\"Output/Semantic_Results\",\n",
    "        device=device,\n",
    "        SAM_checkpoint=\"ckpts/sam_vit_h_4b8939.pth\",\n",
    "        semantic_config=\"configs/SETR_MLA_768x768_80k_base.py\",\n",
    "        semantic_checkpoint=\"ckpts/SETR_MLA/iter_80000.pth\",\n",
    "        model_type=\"vit_h\",\n",
    "        color_list_path=\"FoodSAM/FoodSAM_tools/color_list.npy\",\n",
    "        category_txt=\"FoodSAM/FoodSAM_tools/category_id_files/foodseg103_category_id.txt\",\n",
    "        num_class=104\n",
    "    )\n",
    "\n",
    "    os.makedirs(args.output, exist_ok=True)\n",
    "    write_log(\"Running SAM...\")\n",
    "\n",
    "    # Load m√¥ h√¨nh SAM\n",
    "    sam = sam_model_registry[args.model_type](checkpoint=args.SAM_checkpoint)\n",
    "    sam.to(device=args.device)\n",
    "    write_log(f\"SAM model loaded on {args.device}\")\n",
    "\n",
    "    # Thi·∫øt l·∫≠p b·ªô t·∫°o mask\n",
    "    output_mode = \"binary_mask\"\n",
    "    generator = SamAutomaticMaskGenerator(sam, output_mode=output_mode)\n",
    "\n",
    "    # ƒê·ªçc ·∫£nh v√† th·ª±c hi·ªán segmentation\n",
    "    targets = [args.img_path]\n",
    "    for t in targets:\n",
    "        write_log(f\"Processing {t}...\")\n",
    "        image = cv2.imread(t)\n",
    "        if image is None:\n",
    "            write_log(f\"Kh√¥ng th·ªÉ t·∫£i {t}, b·ªè qua...\")\n",
    "            continue\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        masks = generator.generate(image)\n",
    "\n",
    "        # L∆∞u k·∫øt qu·∫£\n",
    "        base = os.path.basename(t).split('.')[0]\n",
    "        save_base = os.path.join(args.output, base)\n",
    "        os.makedirs(save_base, exist_ok=True)\n",
    "        write_masks_to_folder(masks, save_base)\n",
    "        shutil.copyfile(t, os.path.join(save_base, \"input.jpg\"))\n",
    "\n",
    "    write_log(\"SAM processing done!\")\n",
    "    write_log(\"Running semantic segmentation model...\")\n",
    "    semantic_predict(args.semantic_config, args.semantic_checkpoint,\n",
    "                     args.output, args.color_list_path, args.img_path, device=args.device)\n",
    "    write_log(\"Semantic segmentation done!\")\n",
    "    write_log(\"Enhancing semantic masks...\")\n",
    "    enhance_masks(args.output, args.category_txt,\n",
    "                  args.color_list_path, num_class=args.num_class)\n",
    "    write_log(\"Enhancement done!\")\n",
    "    write_log(f\"Results saved in {args.output}!\")\n",
    "    return base\n",
    "\n",
    "# H√†m ch·∫°y depth estimation v√† t√≠nh kh·ªëi l∆∞·ª£ng (TensorFlow)\n",
    "\n",
    "\n",
    "def run_depth_estimation(image_path, base):\n",
    "    global estimator, global_graph, global_session\n",
    "    # Kh·ªüi t·∫°o l·∫°i estimator v·ªõi graph/session m·ªõi\n",
    "    init_estimator()\n",
    "    with global_graph.as_default():\n",
    "        with global_session.as_default():\n",
    "            K.set_session(global_session)\n",
    "            # B·ªè log summary c·ªßa depth model theo y√™u c·∫ßu\n",
    "\n",
    "            # Ch·∫°y ∆∞·ªõc l∆∞·ª£ng th·ªÉ t√≠ch\n",
    "            plate_diameter = 0  # B·ªè qua ph√°t hi·ªán ƒëƒ©a\n",
    "            outputs_list, food_volumes = estimator.estimate_volume(\n",
    "                image_path, fov=70, plate_diameter_prior=plate_diameter,\n",
    "                plot_results=True, para_folder_path=f\"Output/Semantic_Results/{base}/masks/\"\n",
    "            )\n",
    "\n",
    "            # Chuy·ªÉn ƒë·ªïi th·ªÉ t√≠ch sang kh·ªëi l∆∞·ª£ng\n",
    "            food_masses = estimator.convert_volume_to_mass(\n",
    "                'Density_sub_90.xlsx', food_volumes)\n",
    "            write_log(f\"Food masses: {food_masses}\")\n",
    "\n",
    "            return food_masses\n",
    "\n",
    "# H√†m x·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\n",
    "\n",
    "\n",
    "def process_image_input(image: UploadFile, image_path: str):\n",
    "    if image:\n",
    "        input_folder = \"Input\"\n",
    "        os.makedirs(input_folder, exist_ok=True)\n",
    "        clear_folder(\"Input\")\n",
    "        clear_folder(\"debug\")\n",
    "        clear_folder(\"Output\")\n",
    "        temp_file_path = os.path.join(input_folder, image.filename)\n",
    "        with open(temp_file_path, \"wb\") as temp_file:\n",
    "            shutil.copyfileobj(image.file, temp_file)\n",
    "        return temp_file_path, True\n",
    "    elif image_path:\n",
    "        clear_folder(\"Input\")\n",
    "        clear_folder(\"debug\")\n",
    "        clear_folder(\"Output\")\n",
    "        if not os.path.exists(image_path):\n",
    "            raise ValueError(\n",
    "                f\"The image at path '{image_path}' does not exist.\")\n",
    "        write_log(f\"Using image path: {image_path}\")\n",
    "        return image_path, False\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Please provide either an uploaded image or an image path.\")\n",
    "\n",
    "\n",
    "# Kh·ªüi t·∫°o FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Th√™m c·∫•u h√¨nh CORS ngay sau d√≤ng `app = FastAPI()`\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:8081\"],  # Cho ph√©p URL c·ª• th·ªÉ\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Cho ph√©p t·∫•t c·∫£ c√°c ph∆∞∆°ng th·ª©c (GET, POST, v.v.)\n",
    "    allow_headers=[\"*\"],  # Cho ph√©p t·∫•t c·∫£ c√°c header\n",
    ")\n",
    "\n",
    "# ƒê·∫£m b·∫£o th∆∞ m·ª•c debug t·ªìn t·∫°i\n",
    "os.makedirs(\"debug\", exist_ok=True)\n",
    "\n",
    "# Endpoint FastAPI (chuy·ªÉn sang ƒë·ªìng b·ªô)\n",
    "\n",
    "\n",
    "@app.post(\"/food-mass/\", dependencies=[Depends(lambda: None)])\n",
    "def process_image(image: UploadFile = File(None), image_path: str = None):\n",
    "    try:\n",
    "        # X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o\n",
    "        image_path_to_process, is_uploaded = process_image_input(\n",
    "            image, image_path)\n",
    "\n",
    "        # B∆∞·ªõc 1: Ch·∫°y FoodSAM (PyTorch)\n",
    "        base = run_foodsam(image_path_to_process)\n",
    "\n",
    "        # B∆∞·ªõc 2: Ch·∫°y depth estimation (TensorFlow)\n",
    "        food_masses = run_depth_estimation(image_path_to_process, base)\n",
    "\n",
    "        # X√≥a file t·∫°m n·∫øu c√≥\n",
    "        if is_uploaded:\n",
    "            os.remove(image_path_to_process)\n",
    "\n",
    "        return {\"food_masses_gram\": food_masses}\n",
    "    except Exception as e:\n",
    "        write_log(f\"Error: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Start Get Nutrtion #####################################################################################################################\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a m√¥ h√¨nh d·ªØ li·ªáu ƒë·∫ßu v√†o\n",
    "\n",
    "\n",
    "class FoodItem(BaseModel):\n",
    "    food: str  # T√™n th·ª±c ph·∫©m, v√≠ d·ª•: \"rice\"\n",
    "    mass: float  # Kh·ªëi l∆∞·ª£ng th·ª±c ph·∫©m (gram), v√≠ d·ª•: 258\n",
    "\n",
    "\n",
    "class FoodInput(BaseModel):\n",
    "    food_masses_gram: List[FoodItem]  # Danh s√°ch c√°c th·ª±c ph·∫©m v√† kh·ªëi l∆∞·ª£ng\n",
    "    token: str  # Token ƒë·ªÉ x√°c th·ª±c khi g·ªçi API input_manual\n",
    "\n",
    "\n",
    "# Kh√≥a API c·ªßa USDA ƒë·ªÉ truy c·∫≠p d·ªØ li·ªáu dinh d∆∞·ª°ng\n",
    "API_KEY = \"gP07Q5U7ULsiXCXLbCGVqk4c2Y6Yx39nMWJiuJxx\"\n",
    "\n",
    "\n",
    "async def get_nutrition(food_name: str, weight: float) -> dict:\n",
    "    \"\"\"\n",
    "    L·∫•y d·ªØ li·ªáu dinh d∆∞·ª°ng t·ª´ USDA API cho m·ªôt th·ª±c ph·∫©m.\n",
    "    - ƒê·∫ßu v√†o: food_name (t√™n th·ª±c ph·∫©m), weight (kh·ªëi l∆∞·ª£ng t√≠nh b·∫±ng gram)\n",
    "    - ƒê·∫ßu ra: Dictionary ch·ª©a th√¥ng tin dinh d∆∞·ª°ng theo ƒë·ªãnh d·∫°ng foodLogData\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # G·ª≠i y√™u c·∫ßu HTTP b·∫•t ƒë·ªìng b·ªô t·ªõi USDA API\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            print(f\"ƒêang g·ª≠i y√™u c·∫ßu t·ªõi USDA API cho th·ª±c ph·∫©m: {food_name}\")\n",
    "            url = f\"https://api.nal.usda.gov/fdc/v1/foods/search?query={food_name}&api_key={API_KEY}\"\n",
    "            response = await client.get(url)\n",
    "            response.raise_for_status()  # N√©m l·ªói n·∫øu y√™u c·∫ßu th·∫•t b·∫°i\n",
    "            data = response.json()\n",
    "\n",
    "            # Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu th·ª±c ph·∫©m hay kh√¥ng\n",
    "            if 'foods' in data and len(data['foods']) > 0:\n",
    "                food = data['foods'][0]  # L·∫•y th·ª±c ph·∫©m ƒë·∫ßu ti√™n\n",
    "                nutrients = {nutrient['nutrientName']: nutrient['value']\n",
    "                             for nutrient in food['foodNutrients']}\n",
    "\n",
    "                # Ch·ªçn c√°c ch·∫•t dinh d∆∞·ª°ng c·∫ßn thi·∫øt v√† ƒë·ªïi t√™n ƒë·ªÉ kh·ªõp v·ªõi foodLogData\n",
    "                selected_nutrients = {\n",
    "                    # NƒÉng l∆∞·ª£ng (kcal)\n",
    "                    \"calories\": nutrients.get(\"Energy\", 0),\n",
    "                    \"protein\": nutrients.get(\"Protein\", 0),  # Ch·∫•t ƒë·∫°m (g)\n",
    "                    # Tinh b·ªôt (g)\n",
    "                    \"carbs\": nutrients.get(\"Carbohydrate, by difference\", 0),\n",
    "                    # Ch·∫•t b√©o (g)\n",
    "                    \"fat\": nutrients.get(\"Total lipid (fat)\", 0),\n",
    "                }\n",
    "\n",
    "                # T√≠nh to√°n dinh d∆∞·ª°ng theo kh·ªëi l∆∞·ª£ng (USDA cung c·∫•p d·ªØ li·ªáu cho 100g)\n",
    "                factor = weight / 100\n",
    "                nutrients_scaled = {k: round(v * factor, 2)\n",
    "                                    for k, v in selected_nutrients.items()}\n",
    "\n",
    "                # Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng kh·ªõp v·ªõi foodLogData\n",
    "                result = {\n",
    "                    \"name\": food_name,\n",
    "                    \"grams\": weight,\n",
    "                    **nutrients_scaled\n",
    "                }\n",
    "                write_log(f\"D·ªØ li·ªáu dinh d∆∞·ª°ng cho {food_name}: {result}\")\n",
    "                return result\n",
    "            else:\n",
    "                write_log(\n",
    "                    f\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu cho th·ª±c ph·∫©m '{food_name}'\")\n",
    "                raise ValueError(\n",
    "                    f\"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu cho th·ª±c ph·∫©m '{food_name}'\")\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        write_log(f\"Y√™u c·∫ßu USDA API th·∫•t b·∫°i cho '{food_name}': {str(e)}\")\n",
    "        raise ValueError(f\"Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu cho '{food_name}'\")\n",
    "    except Exception as e:\n",
    "        write_log(f\"L·ªói kh√¥ng mong mu·ªën khi x·ª≠ l√Ω '{food_name}': {str(e)}\")\n",
    "        raise ValueError(f\"L·ªói khi x·ª≠ l√Ω '{food_name}'\")\n",
    "\n",
    "\n",
    "async def post_to_input_manual(food_log_data: list, token: str) -> dict:\n",
    "    \"\"\"\n",
    "    G·ª≠i d·ªØ li·ªáu dinh d∆∞·ª°ng t·ªõi API input_manual.\n",
    "    - ƒê·∫ßu v√†o: food_log_data (danh s√°ch d·ªØ li·ªáu dinh d∆∞·ª°ng), token (chu·ªói x√°c th·ª±c)\n",
    "    - ƒê·∫ßu ra: Dictionary b√°o tr·∫°ng th√°i th√†nh c√¥ng ho·∫∑c th·∫•t b·∫°i\n",
    "    \"\"\"\n",
    "    api_url = \"https://chat.aaateammm.online/api/food-items\"  # URL API th·ª±c t·∫ø\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {token}\"  # Th√™m token v√†o header\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        write_log(f\"ƒêang g·ª≠i d·ªØ li·ªáu t·ªõi API input_manual: {food_log_data}\")\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.post(api_url, json=food_log_data, headers=headers)\n",
    "            response.raise_for_status()  # N√©m l·ªói n·∫øu y√™u c·∫ßu th·∫•t b·∫°i\n",
    "            print(\"G·ª≠i d·ªØ li·ªáu t·ªõi API input_manual th√†nh c√¥ng\")\n",
    "            return {\"status\": \"success\", \"message\": \"G·ª≠i d·ªØ li·ªáu th√†nh c√¥ng\"}\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        write_log(f\"Y√™u c·∫ßu API input_manual th·∫•t b·∫°i: {str(e)}\")\n",
    "        raise HTTPException(status_code=e.response.status_code, detail=str(e))\n",
    "    except Exception as e:\n",
    "        prwrite_logint(\n",
    "            f\"L·ªói kh√¥ng mong mu·ªën khi g·ª≠i t·ªõi API input_manual: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=\"L·ªói m√°y ch·ªß n·ªôi b·ªô\")\n",
    "\n",
    "\n",
    "@app.post(\"/food-nutrition/\")\n",
    "async def get_nutrition_endpoint(food_input: FoodInput):\n",
    "    \"\"\"\n",
    "    X·ª≠ l√Ω danh s√°ch th·ª±c ph·∫©m, l·∫•y d·ªØ li·ªáu dinh d∆∞·ª°ng t·ª´ USDA API, v√† g·ª≠i t·ªõi API input_manual.\n",
    "    - ƒê·∫ßu v√†o: JSON ch·ª©a 'food_masses_gram' (danh s√°ch {food, mass}) v√† 'token'\n",
    "    - ƒê·∫ßu ra: Tr·∫°ng th√°i x·ª≠ l√Ω v√† d·ªØ li·ªáu dinh d∆∞·ª°ng\n",
    "    \"\"\"\n",
    "    try:\n",
    "        write_log(food_input)\n",
    "        # L·∫•y d·ªØ li·ªáu dinh d∆∞·ª°ng cho t·ª´ng th·ª±c ph·∫©m\n",
    "        food_log_data = []\n",
    "\n",
    "        for item in food_input.food_masses_gram:\n",
    "            nutrition = await get_nutrition(item.food, item.mass)\n",
    "            food_log_data.append(nutrition)\n",
    "\n",
    "        if food_input.token.startswith(\"Bearer \"):\n",
    "            food_input.token = food_input.token[len(\"Bearer \"):]\n",
    "\n",
    "        # G·ª≠i d·ªØ li·ªáu t·ªõi API input_manual\n",
    "        result = await post_to_input_manual(food_log_data, food_input.token)\n",
    "\n",
    "        write_log(\"X·ª≠ l√Ω y√™u c·∫ßu th√†nh c√¥ng\")\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"nutrition_data\": food_log_data,\n",
    "            \"api_result\": result\n",
    "        }\n",
    "\n",
    "    except ValueError as e:\n",
    "        write_log(f\"L·ªói: {str(e)}\")\n",
    "        raise HTTPException(status_code=404, detail=str(e))\n",
    "    except Exception as e:\n",
    "        write_log(f\"L·ªói m√°y ch·ªß: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# End Get Nutrtion #####################################################################################################################\n",
    "\n",
    "# H√†m ch·∫°y FastAPI server\n",
    "\n",
    "\n",
    "def start_uvicorn():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n",
    "\n",
    "\n",
    "# Ch·∫°y FastAPI trong thread ri√™ng\n",
    "threading.Thread(target=start_uvicorn, daemon=True).start()\n",
    "\n",
    "# Thi·∫øt l·∫≠p Ngrok\n",
    "ngrok.set_auth_token(\"2wftyZRfXxzSxGhlz427E47c3aW_7RdqiCxQ6CswwCVfvBcDM\")\n",
    "public_url = ngrok.connect(8000)\n",
    "\n",
    "# Log v√† hi·ªÉn th·ªã URL c√¥ng c·ªông\n",
    "write_log(f\"Public URL: {public_url}\")\n",
    "print(\"üöÄ Public FastAPI server is running at:\", public_url)\n",
    "\n",
    "# Gi·ªØ thread ch√≠nh ch·∫°y\n",
    "while True:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"rice_1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import logging\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List\n",
    "import argparse\n",
    "\n",
    "# Th√™m ƒë∆∞·ªùng d·∫´n c√°c th∆∞ vi·ªán t√πy ch·ªânh\n",
    "sys.path.append('.')\n",
    "sys.path.append('./SAM')\n",
    "sys.path.append('./mmseg')\n",
    "\n",
    "# Import c√°c module c·∫ßn thi·∫øt\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "from FoodSAM.FoodSAM_tools.predict_semantic_mask import semantic_predict\n",
    "from FoodSAM.FoodSAM_tools.enhance_semantic_masks import enhance_masks\n",
    "from FoodSAM.FoodSAM_tools.evaluate_foodseg103 import evaluate\n",
    "\n",
    "\n",
    "# T·∫°o ƒë·ªëi t∆∞·ª£ng args thay th·∫ø argparse\n",
    "args = argparse.Namespace(\n",
    "    img_path = image_path,  # C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n ·∫£nh\n",
    "    output=\"Output/Semantic_Results\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    SAM_checkpoint=\"ckpts/sam_vit_h_4b8939.pth\",\n",
    "    semantic_config=\"configs/SETR_MLA_768x768_80k_base.py\",\n",
    "    semantic_checkpoint=\"ckpts/SETR_MLA/iter_80000.pth\",\n",
    "    model_type=\"vit_h\",\n",
    "    color_list_path=\"FoodSAM/FoodSAM_tools/color_list.npy\",\n",
    "    category_txt=\"FoodSAM/FoodSAM_tools/category_id_files/foodseg103_category_id.txt\",\n",
    "    num_class=104\n",
    ")\n",
    "\n",
    "\n",
    "def write_masks_to_folder(masks: List[Dict[str, Any]], path: str) -> None:\n",
    "    \"\"\"L∆∞u c√°c mask c·ªßa SAM v√†o th∆∞ m·ª•c\"\"\"\n",
    "    header = \"id,area,bbox_x0,bbox_y0,bbox_w,bbox_h,point_input_x,point_input_y,predicted_iou,stability_score,crop_box_x0,crop_box_y0,crop_box_w,crop_box_h\"  # noqa\n",
    "    metadata = [header]\n",
    "    os.makedirs(os.path.join(path, \"sam_mask\"), exist_ok=True)\n",
    "    masks_array = []\n",
    "    for i, mask_data in enumerate(masks):\n",
    "        mask = mask_data[\"segmentation\"]\n",
    "        masks_array.append(mask.copy())\n",
    "        filename = f\"{i}.png\"\n",
    "        cv2.imwrite(os.path.join(path, \"sam_mask\", filename), mask * 255)\n",
    "        mask_metadata = [\n",
    "            str(i),\n",
    "            str(mask_data[\"area\"]),\n",
    "            *[str(x) for x in mask_data[\"bbox\"]],\n",
    "            *[str(x) for x in mask_data[\"point_coords\"][0]],\n",
    "            str(mask_data[\"predicted_iou\"]),\n",
    "            str(mask_data[\"stability_score\"]),\n",
    "            *[str(x) for x in mask_data[\"crop_box\"]],\n",
    "        ]\n",
    "        row = \",\".join(mask_metadata)\n",
    "        metadata.append(row)\n",
    "\n",
    "    masks_array = np.stack(masks_array, axis=0)\n",
    "    np.save(os.path.join(path, \"sam_mask\", \"masks.npy\"), masks_array)\n",
    "    metadata_path = os.path.join(path, \"sam_metadata.csv\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(metadata))\n",
    "\n",
    "\n",
    "\n",
    "def create_logger(save_folder):\n",
    "    \"\"\"T·∫°o logger ƒë·ªÉ ghi log trong qu√° tr√¨nh ch·∫°y\"\"\"\n",
    "    log_file = \"sam_process.log\"\n",
    "    final_log_file = os.path.join(save_folder, log_file)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format='[%(asctime)s] [%(filename)s:%(lineno)d] [%(levelname)s] %(message)s',\n",
    "        level=logging.INFO,\n",
    "        handlers=[\n",
    "            logging.FileHandler(final_log_file, mode='w'),\n",
    "            logging.StreamHandler()\n",
    "        ])\n",
    "    logger = logging.getLogger()\n",
    "    print(f\"Logger created: {final_log_file}\")\n",
    "    return logger\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"Ch·∫°y qu√° tr√¨nh segmentation\"\"\"\n",
    "    os.makedirs(args.output, exist_ok=True)\n",
    "    # logger = create_logger(args.output)\n",
    "    # logger.info(\"Running SAM...\")\n",
    "\n",
    "    # Ki·ªÉm tra thi·∫øt b·ªã c√≥ h·ªó tr·ª£ CUDA kh√¥ng\n",
    "    if args.device == \"cuda\" and not torch.cuda.is_available():\n",
    "        # logger.warning(\"CUDA is not available. Switching to CPU.\")\n",
    "        args.device = \"cpu\"\n",
    "\n",
    "    # Load m√¥ h√¨nh SAM\n",
    "    sam = sam_model_registry[args.model_type](checkpoint=args.SAM_checkpoint)\n",
    "    _ = sam.to(device=args.device)\n",
    "\n",
    "    # Thi·∫øt l·∫≠p b·ªô t·∫°o mask\n",
    "    output_mode = \"binary_mask\"\n",
    "    generator = SamAutomaticMaskGenerator(sam, output_mode=output_mode)\n",
    "\n",
    "    assert args.img_path, \"B·∫°n ph·∫£i cung c·∫•p ƒë∆∞·ªùng d·∫´n ·∫£nh.\"\n",
    "    \n",
    "    # ƒê·ªçc ·∫£nh v√† th·ª±c hi·ªán segmentation\n",
    "    targets = [args.img_path]\n",
    "    for t in targets:\n",
    "        # logger.info(f\"Processing {t}...\")\n",
    "        image = cv2.imread(t)\n",
    "        if image is None:\n",
    "            # logger.error(f\"Kh√¥ng th·ªÉ t·∫£i {t}, b·ªè qua...\")\n",
    "            continue\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        masks = generator.generate(image)\n",
    "\n",
    "        # L∆∞u k·∫øt qu·∫£\n",
    "        base = os.path.basename(t).split('.')[0]\n",
    "        save_base = os.path.join(args.output, base)\n",
    "        os.makedirs(save_base, exist_ok=True)\n",
    "        write_masks_to_folder(masks, save_base)\n",
    "        shutil.copyfile(t, os.path.join(save_base, \"input.jpg\"))\n",
    "\n",
    "    # logger.info(\"SAM processing done!\\n\")\n",
    "\n",
    "    # Ch·∫°y m√¥ h√¨nh ph√¢n ƒëo·∫°n ng·ªØ nghƒ©a\n",
    "    # logger.info(\"Running semantic segmentation model...\")\n",
    "    semantic_predict(args.semantic_config, args.semantic_checkpoint,\n",
    "                     args.output, args.color_list_path, args.img_path, device=args.device)\n",
    "    # logger.info(\"Semantic segmentation done!\\n\")\n",
    "\n",
    "    # TƒÉng c∆∞·ªùng segmentation mask\n",
    "    # logger.info(\"Enhancing semantic masks...\")\n",
    "    enhance_masks(args.output, args.category_txt, args.color_list_path, num_class=args.num_class)\n",
    "    # logger.info(\"Enhancement done!\\n\")\n",
    "\n",
    "    # logger.info(f\"Results saved in {args.output}!\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def clear_folder(folder_path: str):\n",
    "    \"\"\"\n",
    "    X√≥a to√†n b·ªô n·ªôi dung b√™n trong th∆∞ m·ª•c (t·∫•t c·∫£ file, th∆∞ m·ª•c con, symbolic link),\n",
    "    nh∆∞ng v·∫´n gi·ªØ l·∫°i th∆∞ m·ª•c g·ªëc.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c c·∫ßn x√≥a n·ªôi dung.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        # Duy·ªát qua t·∫•t c·∫£ file v√† th∆∞ m·ª•c con trong folder\n",
    "        for item in os.listdir(folder_path):\n",
    "            item_path = os.path.join(folder_path, item)\n",
    "            try:\n",
    "                if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "                    os.remove(item_path)  # X√≥a file ho·∫∑c symbolic link\n",
    "                elif os.path.isdir(item_path):\n",
    "                    shutil.rmtree(item_path)  # X√≥a th∆∞ m·ª•c con v√† n·ªôi dung b√™n trong\n",
    "            except Exception as e:\n",
    "                print(f\"L·ªói khi x√≥a {item_path}: {e}\")\n",
    "        print(f\"‚úÖ ƒê√£ x√≥a to√†n b·ªô n·ªôi dung trong th∆∞ m·ª•c '{folder_path}'.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Th∆∞ m·ª•c '{folder_path}' kh√¥ng t·ªìn t·∫°i.\")\n",
    "\n",
    "\n",
    "# clear_folder(\"masks\")\n",
    "# clear_folder(\"Output\")\n",
    "# # Ch·∫°y ch∆∞∆°ng tr√¨nh\n",
    "# main(args)\n",
    "print(\"doneeeeee\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOOD VOLUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from keras.models import Model, model_from_json\n",
    "from food_volume_estimation.volume_estimator import VolumeEstimator\n",
    "from food_volume_estimation.depth_estimation.custom_modules import *\n",
    "from food_volume_estimation.food_segmentation.food_segmentator import FoodSegmentator\n",
    "import matplotlib.pyplot as plt\n",
    "from pyntcloud import PyntCloud\n",
    "\n",
    "# Paths to model archiecture/weights\n",
    "depth_model_architecture = './models/fine_tune_food_videos/monovideo_fine_tune_food_videos.json'\n",
    "depth_model_weights = './models/fine_tune_food_videos/monovideo_fine_tune_food_videos.h5'\n",
    "print(\"loaded model estimate volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator object and intialize\n",
    "estimator = VolumeEstimator(arg_init=False)\n",
    "with open(depth_model_architecture, 'r') as read_file:\n",
    "    custom_losses = Losses()\n",
    "    objs = {'ProjectionLayer': ProjectionLayer,\n",
    "            'ReflectionPadding2D': ReflectionPadding2D,\n",
    "            'InverseDepthNormalization': InverseDepthNormalization,\n",
    "            'AugmentationLayer': AugmentationLayer,\n",
    "            'compute_source_loss': custom_losses.compute_source_loss}\n",
    "    model_architecture_json = json.load(read_file)\n",
    "    estimator.monovideo = model_from_json(model_architecture_json, custom_objects=objs)\n",
    "estimator._VolumeEstimator__set_weights_trainable(estimator.monovideo, False)\n",
    "estimator.monovideo.load_weights(depth_model_weights)\n",
    "estimator.model_input_shape = estimator.monovideo.inputs[0].shape.as_list()[1:]\n",
    "depth_net = estimator.monovideo.get_layer('depth_net')\n",
    "estimator.depth_model = Model(inputs=depth_net.inputs, outputs=depth_net.outputs, name='depth_model')\n",
    "print('[*] Loaded depth estimation model.')\n",
    "\n",
    "# Depth model configuration\n",
    "MIN_DEPTH = 0.01\n",
    "MAX_DEPTH = 10\n",
    "estimator.min_disp = 1 / MAX_DEPTH\n",
    "estimator.max_disp = 1 / MIN_DEPTH\n",
    "estimator.gt_depth_scale = 0.35 # Ground truth expected median depth\n",
    "\n",
    "# Create segmentator object\n",
    "# estimator.segmentator = FoodSegmentator(segmentation_model_weights)\n",
    "\n",
    "# Set plate adjustment relaxation parameter\n",
    "estimator.relax_param = 0.01\n",
    "print(\"done set up model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUTRITION INFORMATION RETRIEAVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√†m ghi log v√†o file\n",
    "def write_log(message):\n",
    "    log_dir = \"debug\"\n",
    "    log_file_path = os.path.join(log_dir, \"log.txt\")\n",
    "\n",
    "    # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Ghi log\n",
    "    with open(log_file_path, \"a\") as log_file:\n",
    "        log_file.write(message + \"\\n\")\n",
    "        \n",
    "def run(image_path_run):\n",
    "    write_log(f\"Starting processing for image: {image_path_run}\")\n",
    "    # T·∫°o ƒë·ªëi t∆∞·ª£ng args thay th·∫ø argparse\n",
    "    args = argparse.Namespace(\n",
    "        img_path=image_path_run,  # C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n ·∫£nh\n",
    "        output=\"Output/Semantic_Results\",\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        SAM_checkpoint=\"ckpts/sam_vit_h_4b8939.pth\",\n",
    "        semantic_config=\"configs/SETR_MLA_768x768_80k_base.py\",\n",
    "        semantic_checkpoint=\"ckpts/SETR_MLA/iter_80000.pth\",\n",
    "        model_type=\"vit_h\",\n",
    "        color_list_path=\"FoodSAM/FoodSAM_tools/color_list.npy\",\n",
    "        category_txt=\"FoodSAM/FoodSAM_tools/category_id_files/foodseg103_category_id.txt\",\n",
    "        num_class=104\n",
    "    )\n",
    "    \n",
    "\n",
    "    clear_folder(\"masks\")\n",
    "    clear_folder(\"Output\")\n",
    "    # Ch·∫°y ch∆∞∆°ng tr√¨nh\n",
    "    main(args)\n",
    "\n",
    "    name_without_ext = os.path.splitext(image_path_run)[0]\n",
    "    write_log(f\"Processed image name without extension: {name_without_ext}\")\n",
    "    # name_without_ext_without_input = name_without_ext.split(\"Input/\")[1]\n",
    "    # write_log(f\"name_without_ext_without_input: {name_without_ext_without_input}\")\n",
    "\n",
    "    plate_diameter = 0  # Set as 0 to ignore plate detection and scaling\n",
    "    outputs_list, food_volumes = estimator.estimate_volume(image_path_run, fov=70, plate_diameter_prior=plate_diameter,\n",
    "                                                        plot_results=True, para_folder_path=rf\"Output/Semantic_Results/{name_without_ext}/masks/\")\n",
    "\n",
    "    food_masses = estimator.convert_volume_to_mass(\n",
    "        r'Density_sub_90.xlsx', food_volumes)\n",
    "    \n",
    "    return food_masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run(r\"rice_1.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit_env",
   "language": "python",
   "name": "vit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
