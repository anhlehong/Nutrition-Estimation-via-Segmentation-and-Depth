{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-image food volume estimation\n",
    "Using a  monocular depth estimation network and a segmentation network, we will estimate the volume of the food displayed in the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, model_from_json\n",
    "from keras import backend as K\n",
    "import nest_asyncio\n",
    "from fastapi import FastAPI, UploadFile, File, Depends\n",
    "import uvicorn\n",
    "from pyngrok import ngrok\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Thêm đường dẫn các thư viện tùy chỉnh\n",
    "sys.path.append('.')\n",
    "sys.path.append('./SAM')\n",
    "sys.path.append('./mmseg')\n",
    "\n",
    "# Import các module cần thiết\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "from FoodSAM.FoodSAM_tools.predict_semantic_mask import semantic_predict\n",
    "from FoodSAM.FoodSAM_tools.enhance_semantic_masks import enhance_masks\n",
    "from food_volume_estimation.volume_estimator import VolumeEstimator\n",
    "from food_volume_estimation.depth_estimation.custom_modules import *\n",
    "\n",
    "# Áp dụng nest_asyncio để chạy FastAPI\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Kiểm tra GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Biến toàn cục cho estimator, graph, session\n",
    "estimator = None\n",
    "global_graph = None\n",
    "global_session = None\n",
    "\n",
    "def init_estimator():\n",
    "    \"\"\"Khởi tạo estimator với graph và session mới\"\"\"\n",
    "    global estimator, global_graph, global_session\n",
    "    # Xóa graph và session hiện tại\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Tạo graph và session mới\n",
    "    global_graph = tf.Graph()\n",
    "    global_session = tf.Session(graph=global_graph)\n",
    "\n",
    "    with global_graph.as_default():\n",
    "        with global_session.as_default():\n",
    "            K.set_session(global_session)\n",
    "            depth_model_architecture = './models/fine_tune_food_videos/monovideo_fine_tune_food_videos.json'\n",
    "            depth_model_weights = './models/fine_tune_food_videos/monovideo_fine_tune_food_videos.h5'\n",
    "            estimator = VolumeEstimator(arg_init=False)\n",
    "            try:\n",
    "                with open(depth_model_architecture, 'r') as read_file:\n",
    "                    custom_losses = Losses()\n",
    "                    objs = {\n",
    "                        'ProjectionLayer': ProjectionLayer,\n",
    "                        'ReflectionPadding2D': ReflectionPadding2D,\n",
    "                        'InverseDepthNormalization': InverseDepthNormalization,\n",
    "                        'AugmentationLayer': AugmentationLayer,\n",
    "                        'compute_source_loss': custom_losses.compute_source_loss\n",
    "                    }\n",
    "                    model_architecture_json = json.load(read_file)\n",
    "                    estimator.monovideo = model_from_json(model_architecture_json, custom_objects=objs)\n",
    "                estimator._VolumeEstimator__set_weights_trainable(estimator.monovideo, False)\n",
    "                global_session.run(tf.global_variables_initializer())\n",
    "                estimator.monovideo.load_weights(depth_model_weights)\n",
    "                estimator.model_input_shape = estimator.monovideo.inputs[0].shape.as_list()[1:]\n",
    "                depth_net = estimator.monovideo.get_layer('depth_net')\n",
    "                estimator.depth_model = Model(inputs=depth_net.inputs, outputs=depth_net.outputs, name='depth_model')\n",
    "                MIN_DEPTH = 0.01\n",
    "                MAX_DEPTH = 10\n",
    "                estimator.min_disp = 1 / MAX_DEPTH\n",
    "                estimator.max_disp = 1 / MIN_DEPTH\n",
    "                estimator.gt_depth_scale = 0.35\n",
    "                estimator.relax_param = 0.01\n",
    "                print('[*] Loaded depth estimation model.')\n",
    "                # Bỏ graph.finalize() để tránh lỗi\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading model: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "# Hàm ghi log\n",
    "def write_log(message):\n",
    "    log_file_path = \"debug/log.txt\"\n",
    "    with open(log_file_path, \"a\") as log_file:\n",
    "        log_file.write(message + \"\\n\")\n",
    "    print(message)\n",
    "\n",
    "# Hàm xóa thư mục\n",
    "def clear_folder(folder_path: str):\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        for item in os.listdir(folder_path):\n",
    "            item_path = os.path.join(folder_path, item)\n",
    "            try:\n",
    "                if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "                    os.remove(item_path)\n",
    "                elif os.path.isdir(item_path):\n",
    "                    shutil.rmtree(item_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi xóa {item_path}: {e}\")\n",
    "        print(f\"✅ Đã xóa toàn bộ nội dung trong thư mục '{folder_path}'.\")\n",
    "    else:\n",
    "        print(f\"⚠️ Thư mục '{folder_path}' không tồn tại.\")\n",
    "\n",
    "# Hàm lưu mask từ SAM\n",
    "def write_masks_to_folder(masks: List[Dict[str, Any]], path: str) -> None:\n",
    "    header = \"id,area,bbox_x0,bbox_y0,bbox_w,bbox_h,point_input_x,point_input_y,predicted_iou,stability_score,crop_box_x0,crop_box_y0,crop_box_w,crop_box_h\"\n",
    "    metadata = [header]\n",
    "    os.makedirs(os.path.join(path, \"sam_mask\"), exist_ok=True)\n",
    "    masks_array = []\n",
    "    for i, mask_data in enumerate(masks):\n",
    "        mask = mask_data[\"segmentation\"]\n",
    "        masks_array.append(mask.copy())\n",
    "        filename = f\"{i}.png\"\n",
    "        cv2.imwrite(os.path.join(path, \"sam_mask\", filename), mask * 255)\n",
    "        mask_metadata = [\n",
    "            str(i),\n",
    "            str(mask_data[\"area\"]),\n",
    "            *[str(x) for x in mask_data[\"bbox\"]],\n",
    "            *[str(x) for x in mask_data[\"point_coords\"][0]],\n",
    "            str(mask_data[\"predicted_iou\"]),\n",
    "            str(mask_data[\"stability_score\"]),\n",
    "            *[str(x) for x in mask_data[\"crop_box\"]],\n",
    "        ]\n",
    "        row = \",\".join(mask_metadata)\n",
    "        metadata.append(row)\n",
    "    masks_array = np.stack(masks_array, axis=0)\n",
    "    np.save(os.path.join(path, \"sam_mask\", \"masks.npy\"), masks_array)\n",
    "    metadata_path = os.path.join(path, \"sam_metadata.csv\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(metadata))\n",
    "\n",
    "# Hàm chạy FoodSAM (PyTorch)\n",
    "def run_foodsam(image_path):\n",
    "    args = argparse.Namespace(\n",
    "        img_path=image_path,\n",
    "        output=\"Output/Semantic_Results\",\n",
    "        device=device,\n",
    "        SAM_checkpoint=\"ckpts/sam_vit_h_4b8939.pth\",\n",
    "        semantic_config=\"configs/SETR_MLA_768x768_80k_base.py\",\n",
    "        semantic_checkpoint=\"ckpts/SETR_MLA/iter_80000.pth\",\n",
    "        model_type=\"vit_h\",\n",
    "        color_list_path=\"FoodSAM/FoodSAM_tools/color_list.npy\",\n",
    "        category_txt=\"FoodSAM/FoodSAM_tools/category_id_files/foodseg103_category_id.txt\",\n",
    "        num_class=104\n",
    "    )\n",
    "\n",
    "    os.makedirs(args.output, exist_ok=True)\n",
    "    write_log(\"Running SAM...\")\n",
    "\n",
    "    # Load mô hình SAM\n",
    "    sam = sam_model_registry[args.model_type](checkpoint=args.SAM_checkpoint)\n",
    "    sam.to(device=args.device)\n",
    "    write_log(f\"SAM model loaded on {args.device}\")\n",
    "\n",
    "    # Thiết lập bộ tạo mask\n",
    "    output_mode = \"binary_mask\"\n",
    "    generator = SamAutomaticMaskGenerator(sam, output_mode=output_mode)\n",
    "\n",
    "    # Đọc ảnh và thực hiện segmentation\n",
    "    targets = [args.img_path]\n",
    "    for t in targets:\n",
    "        write_log(f\"Processing {t}...\")\n",
    "        image = cv2.imread(t)\n",
    "        if image is None:\n",
    "            write_log(f\"Không thể tải {t}, bỏ qua...\")\n",
    "            continue\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        masks = generator.generate(image)\n",
    "\n",
    "        # Lưu kết quả\n",
    "        base = os.path.basename(t).split('.')[0]\n",
    "        save_base = os.path.join(args.output, base)\n",
    "        os.makedirs(save_base, exist_ok=True)\n",
    "        write_masks_to_folder(masks, save_base)\n",
    "        shutil.copyfile(t, os.path.join(save_base, \"input.jpg\"))\n",
    "\n",
    "    write_log(\"SAM processing done!\")\n",
    "    write_log(\"Running semantic segmentation model...\")\n",
    "    semantic_predict(args.semantic_config, args.semantic_checkpoint,\n",
    "                     args.output, args.color_list_path, args.img_path, device=args.device)\n",
    "    write_log(\"Semantic segmentation done!\")\n",
    "    write_log(\"Enhancing semantic masks...\")\n",
    "    enhance_masks(args.output, args.category_txt, args.color_list_path, num_class=args.num_class)\n",
    "    write_log(\"Enhancement done!\")\n",
    "    write_log(f\"Results saved in {args.output}!\")\n",
    "    return base\n",
    "\n",
    "# Hàm chạy depth estimation và tính khối lượng (TensorFlow)\n",
    "def run_depth_estimation(image_path, base):\n",
    "    global estimator, global_graph, global_session\n",
    "    # Khởi tạo lại estimator với graph/session mới\n",
    "    init_estimator()\n",
    "    with global_graph.as_default():\n",
    "        with global_session.as_default():\n",
    "            K.set_session(global_session)\n",
    "            # Bỏ log summary của depth model theo yêu cầu\n",
    "\n",
    "            # Chạy ước lượng thể tích\n",
    "            plate_diameter = 0  # Bỏ qua phát hiện đĩa\n",
    "            outputs_list, food_volumes = estimator.estimate_volume(\n",
    "                image_path, fov=70, plate_diameter_prior=plate_diameter,\n",
    "                plot_results=True, para_folder_path=f\"Output/Semantic_Results/{base}/masks/\"\n",
    "            )\n",
    "\n",
    "            # Chuyển đổi thể tích sang khối lượng\n",
    "            food_masses = estimator.convert_volume_to_mass('Density_sub_90.xlsx', food_volumes)\n",
    "            write_log(f\"Food masses: {food_masses}\")\n",
    "\n",
    "            # Nhập API_KEY của bạn\n",
    "            API_KEY = \"gP07Q5U7ULsiXCXLbCGVqk4c2Y6Yx39nMWJiuJxx\"\n",
    "            \n",
    "            # Lấy dữ liệu dinh dưỡng\n",
    "            nutrition_data = estimator.get_nutrition_for_all(food_masses, API_KEY)\n",
    "            write_log(f\"nutrition_data: {nutrition_data}\")\n",
    "            return nutrition_data\n",
    "\n",
    "# Hàm xử lý ảnh đầu vào\n",
    "def process_image_input(image: UploadFile, image_path: str):\n",
    "    if image:\n",
    "        input_folder = \"Input\"\n",
    "        os.makedirs(input_folder, exist_ok=True)\n",
    "        clear_folder(\"Input\")\n",
    "        clear_folder(\"debug\")\n",
    "        temp_file_path = os.path.join(input_folder, image.filename)\n",
    "        with open(temp_file_path, \"wb\") as temp_file:\n",
    "            shutil.copyfileobj(image.file, temp_file)\n",
    "        return temp_file_path, True\n",
    "    elif image_path:\n",
    "        clear_folder(\"Input\")\n",
    "        clear_folder(\"debug\")\n",
    "        if not os.path.exists(image_path):\n",
    "            raise ValueError(f\"The image at path '{image_path}' does not exist.\")\n",
    "        write_log(f\"Using image path: {image_path}\")\n",
    "        return image_path, False\n",
    "    else:\n",
    "        raise ValueError(\"Please provide either an uploaded image or an image path.\")\n",
    "\n",
    "# Khởi tạo FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Đảm bảo thư mục debug tồn tại\n",
    "os.makedirs(\"debug\", exist_ok=True)\n",
    "\n",
    "# Endpoint FastAPI (chuyển sang đồng bộ)\n",
    "@app.post(\"/process-image/\", dependencies=[Depends(lambda: None)])\n",
    "def process_image(image: UploadFile = File(None), image_path: str = None):\n",
    "    try:\n",
    "        # Xử lý ảnh đầu vào\n",
    "        image_path_to_process, is_uploaded = process_image_input(image, image_path)\n",
    "\n",
    "        # Bước 1: Chạy FoodSAM (PyTorch)\n",
    "        base = run_foodsam(image_path_to_process)\n",
    "\n",
    "        # Bước 2: Chạy depth estimation (TensorFlow)\n",
    "        food_masses = run_depth_estimation(image_path_to_process, base)\n",
    "\n",
    "        # Xóa file tạm nếu có\n",
    "        if is_uploaded:\n",
    "            os.remove(image_path_to_process)\n",
    "\n",
    "        return {\"food_nutrition\": food_masses}\n",
    "    except Exception as e:\n",
    "        write_log(f\"Error: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Hàm chạy FastAPI server\n",
    "def start_uvicorn():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n",
    "\n",
    "# Chạy FastAPI trong thread riêng\n",
    "threading.Thread(target=start_uvicorn, daemon=True).start()\n",
    "\n",
    "# Thiết lập Ngrok\n",
    "ngrok.set_auth_token(\"2w4ttBJNFtLVvtpgIKDbM3ord6S_4ZhiZ62czznikvh3rUnRM\")\n",
    "public_url = ngrok.connect(8000)\n",
    "\n",
    "# Log và hiển thị URL công cộng\n",
    "write_log(f\"Public URL: {public_url}\")\n",
    "print(\"🚀 Public FastAPI server is running at:\", public_url)\n",
    "\n",
    "# Giữ thread chính chạy\n",
    "while True:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777777#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"rice_1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import logging\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List\n",
    "import argparse\n",
    "\n",
    "# Thêm đường dẫn các thư viện tùy chỉnh\n",
    "sys.path.append('.')\n",
    "sys.path.append('./SAM')\n",
    "sys.path.append('./mmseg')\n",
    "\n",
    "# Import các module cần thiết\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "from FoodSAM.FoodSAM_tools.predict_semantic_mask import semantic_predict\n",
    "from FoodSAM.FoodSAM_tools.enhance_semantic_masks import enhance_masks\n",
    "from FoodSAM.FoodSAM_tools.evaluate_foodseg103 import evaluate\n",
    "\n",
    "\n",
    "# Tạo đối tượng args thay thế argparse\n",
    "args = argparse.Namespace(\n",
    "    img_path = image_path,  # Cập nhật đường dẫn ảnh\n",
    "    output=\"Output/Semantic_Results\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    SAM_checkpoint=\"ckpts/sam_vit_h_4b8939.pth\",\n",
    "    semantic_config=\"configs/SETR_MLA_768x768_80k_base.py\",\n",
    "    semantic_checkpoint=\"ckpts/SETR_MLA/iter_80000.pth\",\n",
    "    model_type=\"vit_h\",\n",
    "    color_list_path=\"FoodSAM/FoodSAM_tools/color_list.npy\",\n",
    "    category_txt=\"FoodSAM/FoodSAM_tools/category_id_files/foodseg103_category_id.txt\",\n",
    "    num_class=104\n",
    ")\n",
    "\n",
    "\n",
    "def write_masks_to_folder(masks: List[Dict[str, Any]], path: str) -> None:\n",
    "    \"\"\"Lưu các mask của SAM vào thư mục\"\"\"\n",
    "    header = \"id,area,bbox_x0,bbox_y0,bbox_w,bbox_h,point_input_x,point_input_y,predicted_iou,stability_score,crop_box_x0,crop_box_y0,crop_box_w,crop_box_h\"  # noqa\n",
    "    metadata = [header]\n",
    "    os.makedirs(os.path.join(path, \"sam_mask\"), exist_ok=True)\n",
    "    masks_array = []\n",
    "    for i, mask_data in enumerate(masks):\n",
    "        mask = mask_data[\"segmentation\"]\n",
    "        masks_array.append(mask.copy())\n",
    "        filename = f\"{i}.png\"\n",
    "        cv2.imwrite(os.path.join(path, \"sam_mask\", filename), mask * 255)\n",
    "        mask_metadata = [\n",
    "            str(i),\n",
    "            str(mask_data[\"area\"]),\n",
    "            *[str(x) for x in mask_data[\"bbox\"]],\n",
    "            *[str(x) for x in mask_data[\"point_coords\"][0]],\n",
    "            str(mask_data[\"predicted_iou\"]),\n",
    "            str(mask_data[\"stability_score\"]),\n",
    "            *[str(x) for x in mask_data[\"crop_box\"]],\n",
    "        ]\n",
    "        row = \",\".join(mask_metadata)\n",
    "        metadata.append(row)\n",
    "\n",
    "    masks_array = np.stack(masks_array, axis=0)\n",
    "    np.save(os.path.join(path, \"sam_mask\", \"masks.npy\"), masks_array)\n",
    "    metadata_path = os.path.join(path, \"sam_metadata.csv\")\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(metadata))\n",
    "\n",
    "\n",
    "\n",
    "def create_logger(save_folder):\n",
    "    \"\"\"Tạo logger để ghi log trong quá trình chạy\"\"\"\n",
    "    log_file = \"sam_process.log\"\n",
    "    final_log_file = os.path.join(save_folder, log_file)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format='[%(asctime)s] [%(filename)s:%(lineno)d] [%(levelname)s] %(message)s',\n",
    "        level=logging.INFO,\n",
    "        handlers=[\n",
    "            logging.FileHandler(final_log_file, mode='w'),\n",
    "            logging.StreamHandler()\n",
    "        ])\n",
    "    logger = logging.getLogger()\n",
    "    print(f\"Logger created: {final_log_file}\")\n",
    "    return logger\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"Chạy quá trình segmentation\"\"\"\n",
    "    os.makedirs(args.output, exist_ok=True)\n",
    "    # logger = create_logger(args.output)\n",
    "    # logger.info(\"Running SAM...\")\n",
    "\n",
    "    # Kiểm tra thiết bị có hỗ trợ CUDA không\n",
    "    if args.device == \"cuda\" and not torch.cuda.is_available():\n",
    "        # logger.warning(\"CUDA is not available. Switching to CPU.\")\n",
    "        args.device = \"cpu\"\n",
    "\n",
    "    # Load mô hình SAM\n",
    "    sam = sam_model_registry[args.model_type](checkpoint=args.SAM_checkpoint)\n",
    "    _ = sam.to(device=args.device)\n",
    "\n",
    "    # Thiết lập bộ tạo mask\n",
    "    output_mode = \"binary_mask\"\n",
    "    generator = SamAutomaticMaskGenerator(sam, output_mode=output_mode)\n",
    "\n",
    "    assert args.img_path, \"Bạn phải cung cấp đường dẫn ảnh.\"\n",
    "    \n",
    "    # Đọc ảnh và thực hiện segmentation\n",
    "    targets = [args.img_path]\n",
    "    for t in targets:\n",
    "        # logger.info(f\"Processing {t}...\")\n",
    "        image = cv2.imread(t)\n",
    "        if image is None:\n",
    "            # logger.error(f\"Không thể tải {t}, bỏ qua...\")\n",
    "            continue\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        masks = generator.generate(image)\n",
    "\n",
    "        # Lưu kết quả\n",
    "        base = os.path.basename(t).split('.')[0]\n",
    "        save_base = os.path.join(args.output, base)\n",
    "        os.makedirs(save_base, exist_ok=True)\n",
    "        write_masks_to_folder(masks, save_base)\n",
    "        shutil.copyfile(t, os.path.join(save_base, \"input.jpg\"))\n",
    "\n",
    "    # logger.info(\"SAM processing done!\\n\")\n",
    "\n",
    "    # Chạy mô hình phân đoạn ngữ nghĩa\n",
    "    # logger.info(\"Running semantic segmentation model...\")\n",
    "    semantic_predict(args.semantic_config, args.semantic_checkpoint,\n",
    "                     args.output, args.color_list_path, args.img_path, device=args.device)\n",
    "    # logger.info(\"Semantic segmentation done!\\n\")\n",
    "\n",
    "    # Tăng cường segmentation mask\n",
    "    # logger.info(\"Enhancing semantic masks...\")\n",
    "    enhance_masks(args.output, args.category_txt, args.color_list_path, num_class=args.num_class)\n",
    "    # logger.info(\"Enhancement done!\\n\")\n",
    "\n",
    "    # logger.info(f\"Results saved in {args.output}!\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def clear_folder(folder_path: str):\n",
    "    \"\"\"\n",
    "    Xóa toàn bộ nội dung bên trong thư mục (tất cả file, thư mục con, symbolic link),\n",
    "    nhưng vẫn giữ lại thư mục gốc.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Đường dẫn thư mục cần xóa nội dung.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        # Duyệt qua tất cả file và thư mục con trong folder\n",
    "        for item in os.listdir(folder_path):\n",
    "            item_path = os.path.join(folder_path, item)\n",
    "            try:\n",
    "                if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "                    os.remove(item_path)  # Xóa file hoặc symbolic link\n",
    "                elif os.path.isdir(item_path):\n",
    "                    shutil.rmtree(item_path)  # Xóa thư mục con và nội dung bên trong\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi xóa {item_path}: {e}\")\n",
    "        print(f\"✅ Đã xóa toàn bộ nội dung trong thư mục '{folder_path}'.\")\n",
    "    else:\n",
    "        print(f\"⚠️ Thư mục '{folder_path}' không tồn tại.\")\n",
    "\n",
    "\n",
    "# clear_folder(\"masks\")\n",
    "# clear_folder(\"Output\")\n",
    "# # Chạy chương trình\n",
    "# main(args)\n",
    "print(\"doneeeeee\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOOD VOLUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from keras.models import Model, model_from_json\n",
    "from food_volume_estimation.volume_estimator import VolumeEstimator\n",
    "from food_volume_estimation.depth_estimation.custom_modules import *\n",
    "from food_volume_estimation.food_segmentation.food_segmentator import FoodSegmentator\n",
    "import matplotlib.pyplot as plt\n",
    "from pyntcloud import PyntCloud\n",
    "\n",
    "# Paths to model archiecture/weights\n",
    "depth_model_architecture = './models/fine_tune_food_videos/monovideo_fine_tune_food_videos.json'\n",
    "depth_model_weights = './models/fine_tune_food_videos/monovideo_fine_tune_food_videos.h5'\n",
    "print(\"loaded model estimate volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator object and intialize\n",
    "estimator = VolumeEstimator(arg_init=False)\n",
    "with open(depth_model_architecture, 'r') as read_file:\n",
    "    custom_losses = Losses()\n",
    "    objs = {'ProjectionLayer': ProjectionLayer,\n",
    "            'ReflectionPadding2D': ReflectionPadding2D,\n",
    "            'InverseDepthNormalization': InverseDepthNormalization,\n",
    "            'AugmentationLayer': AugmentationLayer,\n",
    "            'compute_source_loss': custom_losses.compute_source_loss}\n",
    "    model_architecture_json = json.load(read_file)\n",
    "    estimator.monovideo = model_from_json(model_architecture_json, custom_objects=objs)\n",
    "estimator._VolumeEstimator__set_weights_trainable(estimator.monovideo, False)\n",
    "estimator.monovideo.load_weights(depth_model_weights)\n",
    "estimator.model_input_shape = estimator.monovideo.inputs[0].shape.as_list()[1:]\n",
    "depth_net = estimator.monovideo.get_layer('depth_net')\n",
    "estimator.depth_model = Model(inputs=depth_net.inputs, outputs=depth_net.outputs, name='depth_model')\n",
    "print('[*] Loaded depth estimation model.')\n",
    "\n",
    "# Depth model configuration\n",
    "MIN_DEPTH = 0.01\n",
    "MAX_DEPTH = 10\n",
    "estimator.min_disp = 1 / MAX_DEPTH\n",
    "estimator.max_disp = 1 / MIN_DEPTH\n",
    "estimator.gt_depth_scale = 0.35 # Ground truth expected median depth\n",
    "\n",
    "# Create segmentator object\n",
    "# estimator.segmentator = FoodSegmentator(segmentation_model_weights)\n",
    "\n",
    "# Set plate adjustment relaxation parameter\n",
    "estimator.relax_param = 0.01\n",
    "print(\"done set up model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUTRITION INFORMATION RETRIEAVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm ghi log vào file\n",
    "def write_log(message):\n",
    "    log_dir = \"debug\"\n",
    "    log_file_path = os.path.join(log_dir, \"log.txt\")\n",
    "\n",
    "    # Tạo thư mục nếu chưa tồn tại\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Ghi log\n",
    "    with open(log_file_path, \"a\") as log_file:\n",
    "        log_file.write(message + \"\\n\")\n",
    "        \n",
    "def run(image_path_run):\n",
    "    write_log(f\"Starting processing for image: {image_path_run}\")\n",
    "    # Tạo đối tượng args thay thế argparse\n",
    "    args = argparse.Namespace(\n",
    "        img_path=image_path_run,  # Cập nhật đường dẫn ảnh\n",
    "        output=\"Output/Semantic_Results\",\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        SAM_checkpoint=\"ckpts/sam_vit_h_4b8939.pth\",\n",
    "        semantic_config=\"configs/SETR_MLA_768x768_80k_base.py\",\n",
    "        semantic_checkpoint=\"ckpts/SETR_MLA/iter_80000.pth\",\n",
    "        model_type=\"vit_h\",\n",
    "        color_list_path=\"FoodSAM/FoodSAM_tools/color_list.npy\",\n",
    "        category_txt=\"FoodSAM/FoodSAM_tools/category_id_files/foodseg103_category_id.txt\",\n",
    "        num_class=104\n",
    "    )\n",
    "    \n",
    "\n",
    "    clear_folder(\"masks\")\n",
    "    clear_folder(\"Output\")\n",
    "    # Chạy chương trình\n",
    "    main(args)\n",
    "\n",
    "    name_without_ext = os.path.splitext(image_path_run)[0]\n",
    "    write_log(f\"Processed image name without extension: {name_without_ext}\")\n",
    "    # name_without_ext_without_input = name_without_ext.split(\"Input/\")[1]\n",
    "    # write_log(f\"name_without_ext_without_input: {name_without_ext_without_input}\")\n",
    "\n",
    "    plate_diameter = 0  # Set as 0 to ignore plate detection and scaling\n",
    "    outputs_list, food_volumes = estimator.estimate_volume(image_path_run, fov=70, plate_diameter_prior=plate_diameter,\n",
    "                                                        plot_results=True, para_folder_path=rf\"Output/Semantic_Results/{name_without_ext}/masks/\")\n",
    "\n",
    "    food_masses = estimator.convert_volume_to_mass(\n",
    "        r'Density_sub_90.xlsx', food_volumes)\n",
    "    \n",
    "    return food_masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run(r\"rice_1.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit_env",
   "language": "python",
   "name": "vit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
